{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%tensorflow_version 1.x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hnlr20a4tnw-",
        "outputId": "79bb6b61-22b9-4088-df78-5d0c26475c18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow 1.x selected.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow-estimator==1.15.2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9PJlIJ0l6RbH",
        "outputId": "bdb6a492-9bdc-482b-b0be-bfabda1e85f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow-estimator==1.15.2\n",
            "  Downloading tensorflow_estimator-1.15.2-py2.py3-none-any.whl (502 kB)\n",
            "\u001b[?25l\r\u001b[K     |▋                               | 10 kB 18.6 MB/s eta 0:00:01\r\u001b[K     |█▎                              | 20 kB 13.3 MB/s eta 0:00:01\r\u001b[K     |██                              | 30 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |██▋                             | 40 kB 5.8 MB/s eta 0:00:01\r\u001b[K     |███▎                            | 51 kB 3.7 MB/s eta 0:00:01\r\u001b[K     |████                            | 61 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |████▋                           | 71 kB 4.5 MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 81 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 92 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 102 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 112 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 122 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 133 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 143 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 153 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 163 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 174 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 184 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 194 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 204 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 215 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 225 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 235 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 245 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 256 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 266 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 276 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 286 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 296 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 307 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 317 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 327 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 337 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 348 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 358 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 368 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 378 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 389 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 399 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 409 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 419 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 430 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 440 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 450 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 460 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 471 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 481 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 491 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 501 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 502 kB 4.3 MB/s \n",
            "\u001b[?25hInstalling collected packages: tensorflow-estimator\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 1.15.1\n",
            "    Uninstalling tensorflow-estimator-1.15.1:\n",
            "      Successfully uninstalled tensorflow-estimator-1.15.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 1.15.2 requires gast==0.2.2, but you have gast 0.5.3 which is incompatible.\n",
            "tensorflow 1.15.2 requires tensorflow-estimator==1.15.1, but you have tensorflow-estimator 1.15.2 which is incompatible.\n",
            "kapre 0.3.7 requires tensorflow>=2.0.0, but you have tensorflow 1.15.2 which is incompatible.\u001b[0m\n",
            "Successfully installed tensorflow-estimator-2.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oD_neGUk9qcg",
        "outputId": "5afa5080-6234-46b2-8654-6ba3c8b387a9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using TensorFlow backend.\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pickle\n",
        "import cv2\n",
        "from os import listdir\n",
        "from sklearn.preprocessing import LabelBinarizer, MultiLabelBinarizer\n",
        "from keras.models import Sequential\n",
        "from keras.models import load_model\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers import Activation, Flatten, Dropout, Dense\n",
        "from keras import backend as K\n",
        "from keras.preprocessing.image import ImageDataGenerator, img_to_array, array_to_img\n",
        "from keras.optimizers import Adam, SGD, Adagrad\n",
        "from keras.preprocessing import image\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from keras.models import Model\n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.applications.resnet50 import ResNet50\n",
        "from keras.applications.xception import Xception\n",
        "from keras.layers import Conv2D, AveragePooling2D, GlobalAveragePooling2D\n",
        "#import cv2\n",
        "import tensorflow.keras\n",
        "import os\n",
        "#tf.logging.set_verbosity(tf.logging.ERROR)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SeEDubG0EFST",
        "outputId": "d8f64121-f83e-4291-9e8e-d67d9f446c39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1-Gixcfm9qcj"
      },
      "outputs": [],
      "source": [
        "default_image_size = tuple((64,64))\n",
        "image_size = 0\n",
        "directory_root = '/content/drive/MyDrive/plantvillage'\n",
        "width=64\n",
        "height=64\n",
        "depth=3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RGctzQr19qck"
      },
      "outputs": [],
      "source": [
        "def convert_image_to_array(image_dir):\n",
        "    try:\n",
        "        image = cv2.imread(image_dir)\n",
        "        if image is not None :\n",
        "            return cv2.resize(image, default_image_size)\n",
        "            #return img_to_array(image)\n",
        "        else:\n",
        "            return np.array([])\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(\"Error : \".format(e))\n",
        "        return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HUbtf1pW9qcl",
        "outputId": "fff89032-7c7f-45e4-d26a-410d4e2f18c0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sys.version_info(major=3, minor=7, micro=13, releaselevel='final', serial=0)\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "print(sys.version_info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4hdh37Kc9qcm",
        "outputId": "e5e10dd3-8b21-4f9e-a3ec-f4da4d0354a3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading images ...\n",
            "Processing Pepper__bell___Bacterial_spot ...\n",
            "Processing Pepper__bell___healthy ...\n",
            "Processing Potato___Early_blight ...\n",
            "Processing Potato___Late_blight ...\n",
            "Processing Potato___healthy ...\n",
            "Processing Tomato_Bacterial_spot ...\n",
            "Processing Tomato_Early_blight ...\n",
            "Processing Tomato_Late_blight ...\n",
            "Processing Tomato_Leaf_Mold ...\n",
            "Processing Tomato_Septoria_leaf_spot ...\n",
            "Processing Tomato_Spider_mites_Two_spotted_spider_mite ...\n",
            "Processing Tomato__Target_Spot ...\n",
            "Processing Tomato__Tomato_YellowLeaf__Curl_Virus ...\n",
            "Processing Tomato__Tomato_mosaic_virus ...\n",
            "Processing Tomato_healthy ...\n",
            "--- Loading images completed ---\n"
          ]
        }
      ],
      "source": [
        "image_list, label_list =[],[]\n",
        "try:\n",
        "    print(\"Loading images ...\")\n",
        "    root_dir = listdir(directory_root)\n",
        "    for directory in root_dir:\n",
        "        if directory == \".DS_Store\" :\n",
        "            root_dir.remove(directory)\n",
        "            \n",
        "    for plant_folder in root_dir :\n",
        "        #print('gh')\n",
        "#         plant_disease_folder_list = listdir(\" %(root)s/%(sub)s/\" %{'root':directory_root, 'sub':plant_folder})\n",
        "        plant_disease_folder_list = listdir(directory_root+'/'+plant_folder)\n",
        "        #print(plant_disease_folder_list)\n",
        "        \n",
        "        for disease_folder in plant_disease_folder_list:\n",
        "            if disease_folder == \".DS_Store\" :\n",
        "                plant_disease_folder_list.remove(disease_folder)\n",
        "                \n",
        "        for plant_disease_folder in plant_disease_folder_list:\n",
        "            print(\"Processing %s ...\" %plant_disease_folder)\n",
        "            plant_disease_image_list = listdir(directory_root+\"/\"+plant_folder+\"/\"+plant_disease_folder+\"/\")\n",
        "            #print('ghll')\n",
        "            \n",
        "            for single_plant_disease_image in plant_disease_image_list:\n",
        "                if single_plant_disease_image == \".DS_store\":\n",
        "                    plant_disease_image_list.remove(single_plant_disease_image)\n",
        "            \n",
        "            for image in plant_disease_image_list:\n",
        "                image_directory =directory_root+\"/\"+plant_folder+\"/\"+plant_disease_folder+\"/\"+image\n",
        "                #print(image_directory)\n",
        "                if image_directory.endswith(\".jpg\") == True or image_directory.endswith(\".JPG\") == True :\n",
        "                    image_list.append(convert_image_to_array(image_directory))\n",
        "                    label_list.append(plant_disease_folder)\n",
        "                    \n",
        "    print(\"--- Loading images completed ---\")\n",
        "    #print(label_list)\n",
        "    \n",
        "except Exception as e:\n",
        "    print(\"Error : \".format(e))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UsfMIN3A9qcn"
      },
      "outputs": [],
      "source": [
        "image_size = len(image_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gcrI1ZtF9qco",
        "outputId": "409f34d7-bd18-40bf-bb0e-ac6c0895f4be",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Pepper__bell___Bacterial_spot' 'Pepper__bell___healthy'\n",
            " 'Potato___Early_blight' 'Potato___Late_blight' 'Potato___healthy'\n",
            " 'Tomato_Bacterial_spot' 'Tomato_Early_blight' 'Tomato_Late_blight'\n",
            " 'Tomato_Leaf_Mold' 'Tomato_Septoria_leaf_spot'\n",
            " 'Tomato_Spider_mites_Two_spotted_spider_mite' 'Tomato__Target_Spot'\n",
            " 'Tomato__Tomato_YellowLeaf__Curl_Virus' 'Tomato__Tomato_mosaic_virus'\n",
            " 'Tomato_healthy']\n"
          ]
        }
      ],
      "source": [
        "label_binarizer = LabelBinarizer()\n",
        "image_labels = label_binarizer.fit_transform(label_list)\n",
        "#pickle.dump(label_binarizer, open('label_transform.pk1','wb'))\n",
        "n_classes = len(label_binarizer.classes_)\n",
        "\n",
        "print(label_binarizer.classes_)\n",
        "#print"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L4rkOTCd9qcp",
        "outputId": "db63ba71-1226-4e2c-ef60-87062dd708a9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[22. 28.]\n",
            " [49. 64.]]\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "with tf.device('/gpu:0'):\n",
        "    a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')\n",
        "    b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')\n",
        "    c = tf.matmul(a, b)\n",
        "with tf.Session() as sess:\n",
        "    print(sess.run(c))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UpyaJw3k9qcq"
      },
      "outputs": [],
      "source": [
        "\n",
        "# from PIL import Image\n",
        "# for i in range(10):\n",
        "#     image_list[i].shape\n",
        "#     img = Image.fromarray(image_list[i], 'RGB')\n",
        "#     img.save('my'+str(i)+'.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D-Z6TmoD9qcr"
      },
      "outputs": [],
      "source": [
        "np_image_list = np.array(image_list, dtype=np.float16)/225.0 #255?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kRNaf_mc9qcs",
        "outputId": "768b2097-9d97-41cd-e659-04187aa69187",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Splitting data\n"
          ]
        }
      ],
      "source": [
        "print(\"Splitting data\")\n",
        "x_train, x_test, y_train, y_test= train_test_split(np_image_list, image_labels, test_size =0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "m1Vjl7UZ9qcs",
        "outputId": "b4e3ff40-7776-48c3-cd12-7cfd6219f0ca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16508\n",
            "(16508, 64, 64, 3)\n",
            "15\n"
          ]
        }
      ],
      "source": [
        "print(len(x_train))\n",
        "print(x_train.shape)\n",
        "print(n_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZjyasKrR9qcs"
      },
      "outputs": [],
      "source": [
        "aug = ImageDataGenerator(\n",
        "    rotation_range=5, width_shift_range=0.1,\n",
        "    height_shift_range = 0.1,\n",
        "    horizontal_flip = True,\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8mS8PuAR9qct"
      },
      "outputs": [],
      "source": [
        "# aug = ImageDataGenerator(\n",
        "#     rotation_range=0, width_shift_range=0,\n",
        "#     height_shift_range = 0, shear_range=0,\n",
        "#     zoom_range=0, horizontal_flip = True,\n",
        "#     fill_mode='nearest')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IzWVKnsl9qct",
        "outputId": "fac8568c-5e74-465a-a08e-e249eccae242",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 64, 64, 32)        896       \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 64, 64, 32)        128       \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 64, 64, 32)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 21, 21, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 21, 21, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 21, 21, 64)        18496     \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 21, 21, 64)        256       \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 21, 21, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 21, 21, 64)        36928     \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 21, 21, 64)        256       \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 21, 21, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 10, 10, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 10, 10, 64)        256       \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 10, 10, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 10, 10, 128)       73856     \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 10, 10, 128)       512       \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 10, 10, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 10, 10, 128)       147584    \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 10, 10, 128)       512       \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 10, 10, 128)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 5, 5, 128)         0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 5, 5, 128)         512       \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 5, 5, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 3200)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 256)               819456    \n",
            "_________________________________________________________________\n",
            "batch_normalization_8 (Batch (None, 256)               1024      \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 512)               131584    \n",
            "_________________________________________________________________\n",
            "batch_normalization_9 (Batch (None, 512)               2048      \n",
            "_________________________________________________________________\n",
            "activation_7 (Activation)    (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 15)                7695      \n",
            "_________________________________________________________________\n",
            "activation_8 (Activation)    (None, 15)                0         \n",
            "=================================================================\n",
            "Total params: 1,241,999\n",
            "Trainable params: 1,239,247\n",
            "Non-trainable params: 2,752\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = Sequential()\n",
        "inputShape = (height, width, depth)\n",
        "chanDim = -1\n",
        "if K.image_data_format() == \"channels_first\":\n",
        "    inputShape = (depth, height, width)\n",
        "    chanDim= 1\n",
        "    \n",
        "model.add(Conv2D(32, (3, 3), padding=\"same\",input_shape=inputShape))\n",
        "model.add(BatchNormalization(axis=chanDim))\n",
        "model.add(Activation(\"relu\"))\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(3, 3)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
        "model.add(BatchNormalization(axis=chanDim))\n",
        "model.add(Activation(\"relu\"))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
        "model.add(BatchNormalization(axis=chanDim))\n",
        "model.add(Activation(\"relu\"))\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
        "model.add(BatchNormalization(axis=chanDim))\n",
        "model.add(Activation(\"relu\"))\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
        "model.add(BatchNormalization(axis=chanDim))\n",
        "model.add(Activation(\"relu\"))\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "model.add(Dense(512))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "model.add(Dense(n_classes))\n",
        "model.add(Activation(\"softmax\"))\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WNuxiDbd9qcu",
        "outputId": "64a8796d-0a53-41f5-f423-72df4a3ab63e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "n_classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zIT5k8TQ9qcu"
      },
      "outputs": [],
      "source": [
        "# # base_model = VGG16(weights='imagenet', include_top=False)\n",
        "# #base_model = Alex(weights='imagenet', include_top=False)\n",
        "# base_model = InceptionV3(weights='imagenet', include_top=False, input_shape = (64,64,3) )\n",
        "# #base_model = Xception(include_top=False, weights='imagenet')\n",
        "# x = base_model.output\n",
        "# x = GlobalAveragePooling2D()(x)\n",
        "# # let's add a fully-connected layer\n",
        "# x = Dense(75, activation='relu')(x)\n",
        "# y = Dropout(0.3)(x)\n",
        "# # and a logistic layer -- let's say we have 10 classes\n",
        "# predictions = Dense(n_classes, activation='softmax')(y)\n",
        "\n",
        "# model = Model(inputs=base_model.input, outputs=predictions)\n",
        "# print(base_model.input)\n",
        "# # for layser in model.layers:\n",
        "# #    layer.trainable = True\n",
        "# model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A2ox75fj9qcv"
      },
      "outputs": [],
      "source": [
        "# incept = tensorflow.keras.applications.inception_v3.InceptionV3(include_top=False, weights='imagenet', input_tensor=None, input_shape=None, pooling=None)#, classes=1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zaCyYbxi9qcv",
        "outputId": "faf0b2fb-93a0-4c7f-91ea-f022bc7e02c1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training...\n"
          ]
        }
      ],
      "source": [
        "EPOCHS = 30\n",
        "INIT_LR = 0.001\n",
        "BS = 32\n",
        "#opt = SGD(lr=INIT_LR, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "#opt = Adagrad(lr=INIT_LR)\n",
        "opt=Adam(lr=INIT_LR)#, decay=INIT_LR / EPOCHS)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=[\"accuracy\"])\n",
        "\n",
        "print(\"Training...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lkzmgTve9qcv"
      },
      "outputs": [],
      "source": [
        "#y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zMq7ZR6Q9qcv",
        "outputId": "8fb1a149-b96b-4c57-dc0c-6838ecfe1751",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "Epoch 1/30\n",
            "40/40 [==============================] - 7s 171ms/step - loss: 2.3820 - accuracy: 0.2891 - val_loss: 3.2288 - val_accuracy: 0.0766\n",
            "Epoch 2/30\n",
            "40/40 [==============================] - 2s 54ms/step - loss: 1.8222 - accuracy: 0.4203 - val_loss: 4.6387 - val_accuracy: 0.0766\n",
            "Epoch 3/30\n",
            "40/40 [==============================] - 2s 54ms/step - loss: 1.5178 - accuracy: 0.5102 - val_loss: 8.4846 - val_accuracy: 0.0766\n",
            "Epoch 4/30\n",
            "40/40 [==============================] - 2s 54ms/step - loss: 1.3798 - accuracy: 0.5555 - val_loss: 10.3587 - val_accuracy: 0.0766\n",
            "Epoch 5/30\n",
            "40/40 [==============================] - 2s 53ms/step - loss: 1.2188 - accuracy: 0.6102 - val_loss: 7.2015 - val_accuracy: 0.1512\n",
            "Epoch 6/30\n",
            "40/40 [==============================] - 2s 54ms/step - loss: 1.1676 - accuracy: 0.6266 - val_loss: 9.5156 - val_accuracy: 0.1347\n",
            "Epoch 7/30\n",
            "40/40 [==============================] - 2s 54ms/step - loss: 1.1348 - accuracy: 0.6398 - val_loss: 7.0385 - val_accuracy: 0.1705\n",
            "Epoch 8/30\n",
            "40/40 [==============================] - 2s 54ms/step - loss: 1.0207 - accuracy: 0.6523 - val_loss: 7.1392 - val_accuracy: 0.1342\n",
            "Epoch 9/30\n",
            "40/40 [==============================] - 2s 53ms/step - loss: 0.9770 - accuracy: 0.6805 - val_loss: 6.8785 - val_accuracy: 0.1868\n",
            "Epoch 10/30\n",
            "40/40 [==============================] - 2s 58ms/step - loss: 1.0272 - accuracy: 0.6630 - val_loss: 5.4153 - val_accuracy: 0.2003\n",
            "Epoch 11/30\n",
            "40/40 [==============================] - 2s 54ms/step - loss: 0.9353 - accuracy: 0.6883 - val_loss: 3.2508 - val_accuracy: 0.2551\n",
            "Epoch 12/30\n",
            "40/40 [==============================] - 2s 54ms/step - loss: 0.9605 - accuracy: 0.6766 - val_loss: 4.3589 - val_accuracy: 0.2834\n",
            "Epoch 13/30\n",
            "40/40 [==============================] - 2s 55ms/step - loss: 0.8373 - accuracy: 0.7312 - val_loss: 5.6493 - val_accuracy: 0.2183\n",
            "Epoch 14/30\n",
            "40/40 [==============================] - 2s 55ms/step - loss: 0.8515 - accuracy: 0.7100 - val_loss: 6.2925 - val_accuracy: 0.2163\n",
            "Epoch 15/30\n",
            "40/40 [==============================] - 2s 53ms/step - loss: 0.7791 - accuracy: 0.7453 - val_loss: 1.4690 - val_accuracy: 0.6030\n",
            "Epoch 16/30\n",
            "40/40 [==============================] - 2s 54ms/step - loss: 0.7828 - accuracy: 0.7227 - val_loss: 1.4936 - val_accuracy: 0.5850\n",
            "Epoch 17/30\n",
            "40/40 [==============================] - 2s 52ms/step - loss: 0.7561 - accuracy: 0.7383 - val_loss: 1.8039 - val_accuracy: 0.5070\n",
            "Epoch 18/30\n",
            "40/40 [==============================] - 2s 54ms/step - loss: 0.7584 - accuracy: 0.7422 - val_loss: 2.1512 - val_accuracy: 0.4864\n",
            "Epoch 19/30\n",
            "40/40 [==============================] - 2s 53ms/step - loss: 0.7723 - accuracy: 0.7328 - val_loss: 2.4374 - val_accuracy: 0.3743\n",
            "Epoch 20/30\n",
            "40/40 [==============================] - 2s 54ms/step - loss: 0.6781 - accuracy: 0.7648 - val_loss: 1.4627 - val_accuracy: 0.5959\n",
            "Epoch 21/30\n",
            "40/40 [==============================] - 2s 55ms/step - loss: 0.7157 - accuracy: 0.7664 - val_loss: 1.7410 - val_accuracy: 0.5477\n",
            "Epoch 22/30\n",
            "40/40 [==============================] - 2s 54ms/step - loss: 0.7166 - accuracy: 0.7602 - val_loss: 2.0935 - val_accuracy: 0.5465\n",
            "Epoch 23/30\n",
            "40/40 [==============================] - 2s 55ms/step - loss: 0.6583 - accuracy: 0.7727 - val_loss: 0.8601 - val_accuracy: 0.7103\n",
            "Epoch 24/30\n",
            "40/40 [==============================] - 2s 54ms/step - loss: 0.6841 - accuracy: 0.7672 - val_loss: 4.1386 - val_accuracy: 0.3796\n",
            "Epoch 25/30\n",
            "40/40 [==============================] - 2s 55ms/step - loss: 0.6783 - accuracy: 0.7766 - val_loss: 3.3874 - val_accuracy: 0.4612\n",
            "Epoch 26/30\n",
            "40/40 [==============================] - 2s 56ms/step - loss: 0.6476 - accuracy: 0.7922 - val_loss: 0.7472 - val_accuracy: 0.7548\n",
            "Epoch 27/30\n",
            "40/40 [==============================] - 2s 54ms/step - loss: 0.5714 - accuracy: 0.7984 - val_loss: 5.0469 - val_accuracy: 0.2679\n",
            "Epoch 28/30\n",
            "40/40 [==============================] - 2s 54ms/step - loss: 0.6009 - accuracy: 0.7969 - val_loss: 0.7277 - val_accuracy: 0.7544\n",
            "Epoch 29/30\n",
            "40/40 [==============================] - 2s 54ms/step - loss: 0.5763 - accuracy: 0.8039 - val_loss: 8.6312 - val_accuracy: 0.1715\n",
            "Epoch 30/30\n",
            "40/40 [==============================] - 2s 53ms/step - loss: 0.5476 - accuracy: 0.8289 - val_loss: 1.2689 - val_accuracy: 0.6659\n"
          ]
        }
      ],
      "source": [
        "history = model.fit_generator(\n",
        "    aug.flow(x_train, y_train, batch_size=BS),\n",
        "    validation_data=(x_test, y_test),\n",
        "#    steps_per_epoch=len(x_train) /BS,\n",
        "    steps_per_epoch=40,\n",
        "    epochs=EPOCHS, verbose=1\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4I9qZvw29qcw"
      },
      "outputs": [],
      "source": [
        "def step_decay(epoch):\n",
        "    initial_lrate=0.001\n",
        "    drop=0.1\n",
        "    epochs_drop=16.0\n",
        "    lrate=initial_lrate * math.pow(drop,math.floor((1+epoch)/epochs_drop))\n",
        "    return lrate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nNIUqLyL9qcw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b080033-d2ee-4a49-9957-859e3db2dd1c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Not using real-time data augmentation.\n",
            "Train on 16508 samples, validate on 4128 samples\n",
            "Epoch 1/15\n",
            " - 26s - loss: 0.8066 - accuracy: 0.7390 - val_loss: 0.3771 - val_accuracy: 0.8796\n",
            "Epoch 2/15\n",
            " - 24s - loss: 0.5368 - accuracy: 0.8246 - val_loss: 0.3923 - val_accuracy: 0.8643\n",
            "Epoch 3/15\n",
            " - 24s - loss: 0.4258 - accuracy: 0.8581 - val_loss: 0.1853 - val_accuracy: 0.9467\n",
            "Epoch 4/15\n",
            " - 24s - loss: 0.3820 - accuracy: 0.8781 - val_loss: 0.2529 - val_accuracy: 0.9208\n",
            "Epoch 5/15\n",
            " - 24s - loss: 0.3459 - accuracy: 0.8858 - val_loss: 0.1875 - val_accuracy: 0.9331\n",
            "Epoch 6/15\n",
            " - 24s - loss: 0.3312 - accuracy: 0.8905 - val_loss: 0.1723 - val_accuracy: 0.9450\n",
            "Epoch 7/15\n",
            " - 23s - loss: 0.2903 - accuracy: 0.9042 - val_loss: 0.1371 - val_accuracy: 0.9566\n",
            "Epoch 8/15\n",
            " - 23s - loss: 0.2857 - accuracy: 0.9075 - val_loss: 0.1467 - val_accuracy: 0.9540\n",
            "Epoch 9/15\n",
            " - 23s - loss: 0.2790 - accuracy: 0.9084 - val_loss: 0.1247 - val_accuracy: 0.9610\n",
            "Epoch 10/15\n",
            " - 24s - loss: 0.2645 - accuracy: 0.9123 - val_loss: 0.1272 - val_accuracy: 0.9646\n",
            "Epoch 11/15\n",
            " - 24s - loss: 0.2573 - accuracy: 0.9160 - val_loss: 0.1330 - val_accuracy: 0.9586\n",
            "Epoch 12/15\n",
            " - 23s - loss: 0.2389 - accuracy: 0.9223 - val_loss: 0.1412 - val_accuracy: 0.9588\n",
            "Epoch 13/15\n",
            " - 24s - loss: 0.2209 - accuracy: 0.9271 - val_loss: 0.1313 - val_accuracy: 0.9593\n",
            "Epoch 14/15\n",
            " - 24s - loss: 0.2334 - accuracy: 0.9228 - val_loss: 0.1321 - val_accuracy: 0.9586\n",
            "Epoch 15/15\n",
            " - 23s - loss: 0.2160 - accuracy: 0.9296 - val_loss: 0.1134 - val_accuracy: 0.9651\n"
          ]
        }
      ],
      "source": [
        "data_aug = False\n",
        "model.compile(loss='categorical_crossentropy',optimizer=Adam(lr=0.001,decay = 1e-03),metrics=['accuracy'])\n",
        "\n",
        "if not data_aug:\n",
        "    print('Not using real-time data augmentation.')\n",
        "    history = model.fit(x_train,y_train,validation_data=(x_test,y_test),batch_size=8,epochs=15,verbose=2,steps_per_epoch=None)\n",
        "    \n",
        "\n",
        "else:\n",
        "    print('Using real-time data augmentation.')\n",
        "    lr=tensorflow.keras.callbacks.LearningRateScheduler(step_decay)#,verbose=1)\n",
        "   # This will do preprocessing and realtime data augmentation:\n",
        "#     tbCallback=tensorflow.keras.callbacks.TensorBoard(log_dir='./Logs/Tensorboard_Logs', histogram_freq=0, \n",
        "#                                            batch_size=32, write_graph=False, write_grads=False, \n",
        "#                                            write_images=False, embeddings_freq=0, embeddings_layer_names=None, \n",
        "#                                            embeddings_metadata=None)\n",
        "#     checkpoint=tensorflow.keras.callbacks.ModelCheckpoint('./Logs/Checkpoint', monitor='val_loss', \n",
        "#                                                verbose=0, save_best_only=False, \n",
        "#                                                save_weights_only=False, \n",
        "#                                                mode='auto',\n",
        "#                                                period=1)\n",
        "\n",
        "    datagen = ImageDataGenerator(\n",
        "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "        samplewise_center=False,  # set each sample mean to 0\n",
        "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "        samplewise_std_normalization=False,  # divide each input by its std\n",
        "        zca_whitening=False,  # apply ZCA whitening\n",
        "        rotation_range=180,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "        width_shift_range=0.5,  # randomly shift images horizontally (fraction of total width)\n",
        "        height_shift_range=0.5,  # randomly shift images vertically (fraction of total height)\n",
        "        horizontal_flip=True,  # randomly flip images\n",
        "        vertical_flip=True)  # randomly flip images\n",
        "\n",
        "\n",
        "#     Compute quantities required for feature-wise normalization\n",
        "#     (std, mean, and principal components if ZCA whitening is applied).\n",
        "    datagen.fit(x_train)\n",
        "\n",
        "    # Fit the model on the batches generated by datagen.flow().\n",
        "    history = model.fit_generator(datagen.flow(x_train, y_train,batch_size=16),steps_per_epoch=20,epochs=10, validation_data=(x_test,y_test),workers=4)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tf.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3IBRh2hR5mOl",
        "outputId": "cbe1181a-acf9-4b9f-ab9c-8fc0562ad06d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.15.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RGw2pSnD9qcx"
      },
      "outputs": [],
      "source": [
        "#print(\"Saving model...\")\n",
        "#pickle.dump(model,open('cnn_model.pk1','wb'))\n",
        "model.save('my_model.h5') "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "iCzoypjqFGLk"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "Plant_disease.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}